# Jigsaw---Agile-Community-Rules-Classification
## 自分の解法
- debertaにLLRDを適用
- ファインチューニング済みのLLAMAにpseudo training
- bgeで埋め込み作成→triplet lossでmetric learning
- 評価指標がAUCだからランク平均

## 他に試したこと
- qwen3 7bを使ってデータ生成　→　質のいいデータが作れなくて断念
- deberta + cnnのハイブリット　→　ほとんど意味なかった
- bge + lightgbm　→　類似度系特徴量を入れるとそこそこいいとこまで行った　でも実行時間の関係から除外
- fasttext + lightgbm　→ 微妙　多分文脈を捉えられる手法じゃないと歯がたたない

## 上位解法のメモ
### 18位の人
- qwen3 32b（学習はなし）でパラフレーズ　→ １から作るんじゃなくて一部だけをパラフレーズすればある程度質は担保できたはず</br>
プロンプトで方向性を保持して言い換え生成</br>
"No promotion of illegal activity": { "violation": "Rewrite this comment using different words while keeping its promotion or encouragement of illegal activities.", "compliant": "Rewrite this comment using different words while keeping it legal and compliant.", },
- unsloth * DDPで学習</br>
unsloth : ファインチューニングを高速化するためのライブラリ</br>
DDP : 同じモデルを各gpuにコピーして並列学習させる手法(kaggle gpuでできる？)</br>
### 12位の人
- 未ラベルのreddit 本文に対してLLM(claude)で違反率を判定させ、擬似ラベルを作成(違反率１％以下のサブレディットは除外)　→ debertaで事前学習　→ コンペデータで再学習
- 未ラベルの集合の多くがテストデータと母集団だったことが寄与しているかも



